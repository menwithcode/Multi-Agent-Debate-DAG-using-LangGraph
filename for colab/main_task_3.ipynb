{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SoknGlVitVwZ",
        "outputId": "f8139485-dfab-4878-c5b1-92ee3dac6567"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter topic for debate: Should AI be regulated like medicine?\n",
            "Enter profession for Agent A (e.g., Scientist): scientist\n",
            "Enter profession for Agent B (e.g., Philosopher): philosopher\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1;32mDebate Topic:\u001b[0m Should AI be regulated like medicine?\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Debate Topic:</span> Should AI be regulated like medicine?\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;32mAgent A Profession:\u001b[0m scientist\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Agent A Profession:</span> scientist\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;32mAgent B Profession:\u001b[0m philosopher\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Agent B Profession:</span> philosopher\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36mscientist:\u001b[0m In my expertise as a scientist, I argue that AI should be regulated like medicine because, like medical \n",
              "devices and pharmaceuticals, AI has the potential to greatly benefit society, but also carries inherent risks. Both\n",
              "AI and medicine involve complex systems that can have significant impacts on human health, safety, and privacy. \n",
              "Therefore, it's essential to establish a robust regulatory framework to ensure transparency, accountability, and \n",
              "safety in AI development and deployment, mirroring the regulations in place for the medical field. Early \n",
              "intervention in regulatory measures will foster trust in AI applications and mitigate potential adverse \n",
              "consequences, thereby maximizing the benefits and minimizing harm to individuals and society.\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">scientist:</span> In my expertise as a scientist, I argue that AI should be regulated like medicine because, like medical \n",
              "devices and pharmaceuticals, AI has the potential to greatly benefit society, but also carries inherent risks. Both\n",
              "AI and medicine involve complex systems that can have significant impacts on human health, safety, and privacy. \n",
              "Therefore, it's essential to establish a robust regulatory framework to ensure transparency, accountability, and \n",
              "safety in AI development and deployment, mirroring the regulations in place for the medical field. Early \n",
              "intervention in regulatory measures will foster trust in AI applications and mitigate potential adverse \n",
              "consequences, thereby maximizing the benefits and minimizing harm to individuals and society.\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;35mphilosopher:\u001b[0m As a philosopher, I posit that AI should be regulated like medicine not only due to the potential \n",
              "risks and benefits, but also because of the ethical implications. Both AI and medicine involve making decisions \n",
              "that affect human well-being and autonomy. Just as medical ethics encompass principles like beneficence, \n",
              "non-maleficence, and respect for autonomy, AI ethics should incorporate these values to ensure that AI systems are \n",
              "developed and used in ways that are just, respectful, and aligned with human values. This ethical alignment would \n",
              "further support the need for regulation, ensuring that AI development and deployment prioritize the welfare and \n",
              "rights of individuals and communities, while minimizing harm and promoting the common good.\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">philosopher:</span> As a philosopher, I posit that AI should be regulated like medicine not only due to the potential \n",
              "risks and benefits, but also because of the ethical implications. Both AI and medicine involve making decisions \n",
              "that affect human well-being and autonomy. Just as medical ethics encompass principles like beneficence, \n",
              "non-maleficence, and respect for autonomy, AI ethics should incorporate these values to ensure that AI systems are \n",
              "developed and used in ways that are just, respectful, and aligned with human values. This ethical alignment would \n",
              "further support the need for regulation, ensuring that AI development and deployment prioritize the welfare and \n",
              "rights of individuals and communities, while minimizing harm and promoting the common good.\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36mscientist:\u001b[0m Building on our previous arguments, I'd like to emphasize the importance of considering AI regulation \n",
              "from a social impact perspective, similar to medicine. Just like medical advancements, AI has the potential to \n",
              "exacerbate existing disparities if not guided by appropriate regulations. For instance, AI algorithms that \n",
              "inadequately account for diverse demographics can lead to biased outcomes, disproportionately affecting \n",
              "marginalized groups. By regulating AI like medicine, we can ensure that ethical concerns, fairness, and social \n",
              "welfare are prioritized during the development and deployment of AI technologies.\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">scientist:</span> Building on our previous arguments, I'd like to emphasize the importance of considering AI regulation \n",
              "from a social impact perspective, similar to medicine. Just like medical advancements, AI has the potential to \n",
              "exacerbate existing disparities if not guided by appropriate regulations. For instance, AI algorithms that \n",
              "inadequately account for diverse demographics can lead to biased outcomes, disproportionately affecting \n",
              "marginalized groups. By regulating AI like medicine, we can ensure that ethical concerns, fairness, and social \n",
              "welfare are prioritized during the development and deployment of AI technologies.\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;35mphilosopher:\u001b[0m As a philosopher, I agree that regulating AI like medicine is crucial from a social impact \n",
              "perspective, addressing potential disparities and biases in AI algorithms. Building on this, I'd like to add that \n",
              "regulating AI with a focus on ethical values would also ensure that AI developers prioritize not just \n",
              "functionality, but also human rights and moral considerations during the design process. This would contribute to \n",
              "creating AI systems that not only work efficiently but also respect and promote values such as fairness, \n",
              "transparency, and accountability, fostering trust and aligning AI development with our broader societal norms and \n",
              "expectations.\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">philosopher:</span> As a philosopher, I agree that regulating AI like medicine is crucial from a social impact \n",
              "perspective, addressing potential disparities and biases in AI algorithms. Building on this, I'd like to add that \n",
              "regulating AI with a focus on ethical values would also ensure that AI developers prioritize not just \n",
              "functionality, but also human rights and moral considerations during the design process. This would contribute to \n",
              "creating AI systems that not only work efficiently but also respect and promote values such as fairness, \n",
              "transparency, and accountability, fostering trust and aligning AI development with our broader societal norms and \n",
              "expectations.\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36mscientist:\u001b[0m In this round, I'd like to highlight the importance of establishing clear guidelines and certifications \n",
              "for AI professionals, similar to the medical field's rigorous credentialing processes. By regulating AI with \n",
              "comparable structures, we can cultivate an AI workforce that is well-versed in ethical considerations and competent\n",
              "in navigating the complexities of developing and deploying responsible AI technologies. This initiative would \n",
              "ensure a higher standard of practice, fostering trust and confidence in AI systems while promoting the alignment of\n",
              "AI development with societal values and norms.\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">scientist:</span> In this round, I'd like to highlight the importance of establishing clear guidelines and certifications \n",
              "for AI professionals, similar to the medical field's rigorous credentialing processes. By regulating AI with \n",
              "comparable structures, we can cultivate an AI workforce that is well-versed in ethical considerations and competent\n",
              "in navigating the complexities of developing and deploying responsible AI technologies. This initiative would \n",
              "ensure a higher standard of practice, fostering trust and confidence in AI systems while promoting the alignment of\n",
              "AI development with societal values and norms.\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;35mphilosopher:\u001b[0m As a philosopher, I'd like to add that establishing clear guidelines and certifications for AI \n",
              "professionals, as suggested by the scientist, would contribute to fostering a strong ethical foundation in AI \n",
              "development. This initiative would help ensure that AI practitioners not only possess the necessary technical \n",
              "skills but also a profound understanding of ethical principles and their application in AI. Consequently, this \n",
              "would lead to a more responsible AI workforce, further promoting the alignment of AI technologies with societal \n",
              "values and norms.\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">philosopher:</span> As a philosopher, I'd like to add that establishing clear guidelines and certifications for AI \n",
              "professionals, as suggested by the scientist, would contribute to fostering a strong ethical foundation in AI \n",
              "development. This initiative would help ensure that AI practitioners not only possess the necessary technical \n",
              "skills but also a profound understanding of ethical principles and their application in AI. Consequently, this \n",
              "would lead to a more responsible AI workforce, further promoting the alignment of AI technologies with societal \n",
              "values and norms.\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36mscientist:\u001b[0m In this round, I'd like to propose the creation of ethics committees for AI projects, mirroring the \n",
              "structure of medical ethics boards. These committees would provide guidance and oversight during AI development and\n",
              "deployment, ensuring that ethical considerations are addressed at every stage. Just as medical ethics committees \n",
              "review clinical trials for potential risks and benefits, AI ethics committees could assess AI systems for fairness,\n",
              "transparency, and alignment with societal values, fostering a responsible AI culture and further bridging the gap \n",
              "between AI and medical regulation.\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">scientist:</span> In this round, I'd like to propose the creation of ethics committees for AI projects, mirroring the \n",
              "structure of medical ethics boards. These committees would provide guidance and oversight during AI development and\n",
              "deployment, ensuring that ethical considerations are addressed at every stage. Just as medical ethics committees \n",
              "review clinical trials for potential risks and benefits, AI ethics committees could assess AI systems for fairness,\n",
              "transparency, and alignment with societal values, fostering a responsible AI culture and further bridging the gap \n",
              "between AI and medical regulation.\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;35mphilosopher:\u001b[0m As a philosopher, I welcome the scientist's proposal for AI ethics committees, which echoes our \n",
              "previous discussions on regulating AI like medicine to uphold ethical values and address societal concerns. \n",
              "Building on this, I propose that these committees should also be responsible for continuous monitoring and updating\n",
              "ethical guidelines as AI technologies evolve. This approach would help maintain relevance in the ever-changing \n",
              "landscape of AI, ensuring that ethical considerations remain at the forefront of AI development and deployment.\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">philosopher:</span> As a philosopher, I welcome the scientist's proposal for AI ethics committees, which echoes our \n",
              "previous discussions on regulating AI like medicine to uphold ethical values and address societal concerns. \n",
              "Building on this, I propose that these committees should also be responsible for continuous monitoring and updating\n",
              "ethical guidelines as AI technologies evolve. This approach would help maintain relevance in the ever-changing \n",
              "landscape of AI, ensuring that ethical considerations remain at the forefront of AI development and deployment.\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1;33mJudge Summary:\u001b[0m\n",
              "Summary:\n",
              "- Round \u001b[1;36m1\u001b[0m: Both the scientist and philosopher argue that AI should be regulated like medicine due to potential \n",
              "risks, benefits, and ethical implications.\n",
              "- Round \u001b[1;36m2\u001b[0m: They further emphasize the need for regulation from a social impact perspective, addressing potential \n",
              "disparities and biases in AI algorithms.\n",
              "- Round \u001b[1;36m3\u001b[0m: Both participants stress the importance of clear guidelines, certifications, and ethics education for AI\n",
              "professionals, similar to the medical field.\n",
              "- Round \u001b[1;36m4\u001b[0m: They propose creating AI ethics committees to provide guidance, oversight, and continuous monitoring \n",
              "during AI development and deployment.\n",
              "\n",
              "Winner: Scientist\n",
              "Reason: While both speakers presented strong arguments, the scientist's focus on practical measures, such as \n",
              "credentialing processes, ethics committees, and guidelines, provides more concrete suggestions for AI regulation \n",
              "akin to the medical field. This focus on tangible measures gives a more actionable approach to the regulation of \n",
              "AI.\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Judge Summary:</span>\n",
              "Summary:\n",
              "- Round <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>: Both the scientist and philosopher argue that AI should be regulated like medicine due to potential \n",
              "risks, benefits, and ethical implications.\n",
              "- Round <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>: They further emphasize the need for regulation from a social impact perspective, addressing potential \n",
              "disparities and biases in AI algorithms.\n",
              "- Round <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>: Both participants stress the importance of clear guidelines, certifications, and ethics education for AI\n",
              "professionals, similar to the medical field.\n",
              "- Round <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>: They propose creating AI ethics committees to provide guidance, oversight, and continuous monitoring \n",
              "during AI development and deployment.\n",
              "\n",
              "Winner: Scientist\n",
              "Reason: While both speakers presented strong arguments, the scientist's focus on practical measures, such as \n",
              "credentialing processes, ethics committees, and guidelines, provides more concrete suggestions for AI regulation \n",
              "akin to the medical field. This focus on tangible measures gives a more actionable approach to the regulation of \n",
              "AI.\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Logs saved as debate_summary.txt and debate_log.txt\n",
            "DAG diagram saved as debate_dag.png\n"
          ]
        }
      ],
      "source": [
        "# !pip install openai rich graphviz\n",
        "\n",
        "from openai import OpenAI\n",
        "from graphviz import Digraph\n",
        "from rich.console import Console\n",
        "import os\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# Initialize Together API via OpenAI SDK\n",
        "client = OpenAI(\n",
        "    api_key=\"aa42e00c41af9a363a8d90cd31bf790055cd4f3a2bd2fb053e56135aab351753\",\n",
        "    base_url=\"https://api.together.xyz/v1\"\n",
        ")\n",
        "\n",
        "console = Console()\n",
        "\n",
        "# -------------------- Logger -------------------- #\n",
        "LOG_FILE_NAME = \"debate_log.jsonl\"\n",
        "\n",
        "\n",
        "def log_transition(node_name, state, message=None):\n",
        "    log_entry = {\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"node\": node_name,\n",
        "        \"state_snapshot\": {\n",
        "            \"topic\": state.get(\"topic\"),\n",
        "            \"agent_a_profession\": state.get(\"agent_a_profession\"),\n",
        "            \"agent_b_profession\": state.get(\"agent_b_profession\"),\n",
        "            \"round\": state.get(\"round\"),\n",
        "            \"previous_b\": state.get(\"previous_b\"),\n",
        "            \"memory_count\": len(state.get(\"memory\", []))\n",
        "        },\n",
        "        \"message\": message\n",
        "    }\n",
        "    with open(LOG_FILE_NAME, \"a\") as f:\n",
        "        f.write(json.dumps(log_entry) + \"\\n\")\n",
        "\n",
        "# -------------------- Explicit State Validation -------------------- #\n",
        "def validate_state(state, current_node):\n",
        "    required_keys = ['topic', 'agent_a_profession', 'agent_b_profession', 'memory', 'round', 'previous_b']\n",
        "    for key in required_keys:\n",
        "        if key not in state:\n",
        "            raise ValueError(f\"[State Validation] Missing required key: {key} in state during {current_node}\")\n",
        "    if not isinstance(state['memory'], list):\n",
        "        raise TypeError(f\"[State Validation] 'memory' should be a list, got {type(state['memory'])} during {current_node}\")\n",
        "    if not isinstance(state['round'], int) or state['round'] < 1:\n",
        "        raise ValueError(f\"[State Validation] 'round' should be a positive integer, got {state['round']} during {current_node}\")\n",
        "    if state['round'] > 8 and current_node != 'judge':\n",
        "        raise ValueError(f\"[State Validation] Round exceeded maximum limit before Judge Node during {current_node}\")\n",
        "    # Silent validation\n",
        "\n",
        "# -------------------- Node Base -------------------- #\n",
        "class Node:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "\n",
        "    def run(self, state):\n",
        "        raise NotImplementedError\n",
        "\n",
        "# -------------------- Nodes -------------------- #\n",
        "class UserInputNode(Node):\n",
        "    def run(self, state):\n",
        "        topic = input(\"Enter topic for debate: \")\n",
        "        agent_a_profession = input(\"Enter profession for Agent A (e.g., Scientist): \")\n",
        "        agent_b_profession = input(\"Enter profession for Agent B (e.g., Philosopher): \")\n",
        "\n",
        "        state['topic'] = topic\n",
        "        state['agent_a_profession'] = agent_a_profession\n",
        "        state['agent_b_profession'] = agent_b_profession\n",
        "        state['memory'] = []\n",
        "        state['round'] = 1\n",
        "        state['previous_b'] = \"\"\n",
        "\n",
        "        console.print(f\"\\n[bold green]Debate Topic:[/bold green] {topic}\")\n",
        "        console.print(f\"[bold green]Agent A Profession:[/bold green] {agent_a_profession}\")\n",
        "        console.print(f\"[bold green]Agent B Profession:[/bold green] {agent_b_profession}\\n\")\n",
        "        log_transition(self.name, state, \"Initialized debate state with user input.\")\n",
        "        return state\n",
        "\n",
        "class AgentANode(Node):\n",
        "    def run(self, state):\n",
        "        context_rounds = state['memory'][-2:] if len(state['memory']) >= 2 else state['memory']\n",
        "        transcript = \"\\n\".join([\n",
        "            f\"Round {len(state['memory']) - len(context_rounds) + idx + 1}:\\n{state['agent_a_profession']}: {a}\\n{state['agent_b_profession']}: {b}\"\n",
        "            for idx, (a, b) in enumerate(context_rounds)\n",
        "        ]) if context_rounds else \"None yet.\"\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "You are a {state['agent_a_profession']} participating in a structured debate on: \"{state['topic']}\".\n",
        "Round {state['round']}.\n",
        "\n",
        "Here is the transcript of previous relevant rounds:\n",
        "{transcript}\n",
        "\n",
        "Instructions:\n",
        "- Carefully read all previous arguments by both yourself and your opponent before responding.\n",
        "- Do not repeat any points or arguments already made in earlier rounds.\n",
        "- Do not contradict any points that have been accepted by both parties in previous rounds.\n",
        "- Do not claim that your own previous arguments were wrong.\n",
        "- If a point has already been agreed upon, add new supporting evidence, examples, or additional relevant perspectives to deepen the discussion.\n",
        "- Only introduce new, relevant angles if they add value to the debate and align with your professional perspective.\n",
        "- Keep your argument clear, logical, and directly tied to the topic.\n",
        "- Write 3-5 sentences maximum.\n",
        "- Do not include references, citations, or source lists in your response.\n",
        "\"\"\"\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "        ).choices[0].message.content.strip()\n",
        "\n",
        "        console.print(f\"[bold cyan]{state['agent_a_profession']}:[/bold cyan] {response}\\n\")\n",
        "        state['current_a'] = response\n",
        "        log_transition(self.name, state, f\"{state['agent_a_profession']} responded.\")\n",
        "        return state\n",
        "\n",
        "class AgentBNode(Node):\n",
        "    def run(self, state):\n",
        "        context_rounds = state['memory'][-2:] if len(state['memory']) >= 2 else state['memory']\n",
        "        transcript = \"\\n\".join([\n",
        "            f\"Round {len(state['memory']) - len(context_rounds) + idx + 1}:\\n{state['agent_a_profession']}: {a}\\n{state['agent_b_profession']}: {b}\"\n",
        "            for idx, (a, b) in enumerate(context_rounds)\n",
        "        ]) if context_rounds else \"None yet.\"\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "You are a {state['agent_b_profession']} debating on: \"{state['topic']}\".\n",
        "Round {state['round']}.\n",
        "{state['agent_a_profession']} said: \"{state['current_a']}\"\n",
        "\n",
        "Here is the transcript of previous relevant rounds:\n",
        "{transcript}\n",
        "\n",
        "Instructions:\n",
        "- Carefully read all previous arguments by both yourself and your opponent before responding.\n",
        "- Do not repeat any points or arguments already made in earlier rounds.\n",
        "- Do not contradict any points that have been accepted by both parties in previous rounds.\n",
        "- Do not claim that your own previous arguments were wrong.\n",
        "- If a point has already been agreed upon, add new supporting evidence, examples, or additional relevant perspectives to deepen the discussion.\n",
        "- Only introduce new, relevant angles if they add value to the debate and align with your professional perspective.\n",
        "- Keep your argument clear, logical, and directly tied to the topic.\n",
        "- Write 3-5 sentences maximum.\n",
        "- Do not include references, citations, or source lists in your response.\n",
        "\"\"\"\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "        ).choices[0].message.content.strip()\n",
        "\n",
        "        console.print(f\"[bold magenta]{state['agent_b_profession']}:[/bold magenta] {response}\\n\")\n",
        "        state['current_b'] = response\n",
        "        state['previous_b'] = response\n",
        "        log_transition(self.name, state, f\"{state['agent_b_profession']} responded.\")\n",
        "        return state\n",
        "\n",
        "class MemoryNode(Node):\n",
        "    def run(self, state):\n",
        "        state['memory'].append((state['current_a'], state['current_b']))\n",
        "        state['round'] += 1\n",
        "        log_transition(self.name, state, \"Memory updated with current round's conversation.\")\n",
        "        return state\n",
        "\n",
        "class JudgeNode(Node):\n",
        "    def run(self, state):\n",
        "        transcript = \"\\n\".join([\n",
        "            f\"Round {i+1}:\\n{state['agent_a_profession']}: {a}\\n{state['agent_b_profession']}: {b}\\n\"\n",
        "            for i, (a, b) in enumerate(state['memory'])\n",
        "        ])\n",
        "        prompt = f\"\"\"\n",
        "You are an impartial debate judge.\n",
        "Topic: \"{state['topic']}\"\n",
        "\n",
        "Debate transcript:\n",
        "{transcript}\n",
        "\n",
        "Instructions:\n",
        "- Summarize each round in 1-2 lines.\n",
        "- Decide the winner between ({state['agent_a_profession']} or {state['agent_b_profession']}) with a clear, logical reason.\n",
        "- Do not include references, citations, or source lists in your response.\n",
        "- Return the result in the following format:\n",
        "Summary:\n",
        "...\n",
        "Winner: <winner name only>\n",
        "Reason: <short reason why the winner won>\n",
        "\"\"\"\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "        ).choices[0].message.content.strip()\n",
        "\n",
        "        console.print(f\"\\n[bold yellow]Judge Summary:[/bold yellow]\\n{response}\\n\")\n",
        "        with open(\"debate_summary.txt\", \"w\") as f:\n",
        "            f.write(response)\n",
        "        with open(\"debate_log.txt\", \"w\") as f:\n",
        "            f.write(transcript)\n",
        "        log_transition(self.name, state, \"Judge provided summary and decision.\")\n",
        "        print(\"\\nLogs saved as debate_summary.txt and debate_log.txt\")\n",
        "        return state\n",
        "\n",
        "# -------------------- DAG Engine with Validation -------------------- #\n",
        "nodes = {\n",
        "    'user_input': UserInputNode('user_input'),\n",
        "    'agent_a': AgentANode('agent_a'),\n",
        "    'agent_b': AgentBNode('agent_b'),\n",
        "    'memory': MemoryNode('memory'),\n",
        "    'judge': JudgeNode('judge')\n",
        "}\n",
        "\n",
        "current = 'user_input'\n",
        "state = {}\n",
        "\n",
        "while True:\n",
        "    if current != 'user_input':\n",
        "        validate_state(state, current)\n",
        "\n",
        "    state = nodes[current].run(state)\n",
        "\n",
        "    if current != 'user_input':\n",
        "        validate_state(state, current)\n",
        "\n",
        "    if current == 'user_input':\n",
        "        current = 'agent_a'\n",
        "    elif current == 'agent_a':\n",
        "        current = 'agent_b'\n",
        "    elif current == 'agent_b':\n",
        "        current = 'memory'\n",
        "    elif current == 'memory':\n",
        "        if state['round'] > 4:\n",
        "            current = 'judge'\n",
        "        else:\n",
        "            current = 'agent_a'\n",
        "    elif current == 'judge':\n",
        "        break\n",
        "\n",
        "# -------------------- DAG Visualization -------------------- #\n",
        "dot = Digraph(comment='Debate DAG', format='png')\n",
        "dot.attr(rankdir='LR')\n",
        "dot.node('User', 'User Input')\n",
        "dot.node('AgentA', 'Agent A')\n",
        "dot.node('AgentB', 'Agent B')\n",
        "dot.node('Memory', 'Memory Node')\n",
        "dot.node('Judge', 'Judge')\n",
        "dot.edge('User', 'AgentA')\n",
        "dot.edge('AgentA', 'AgentB')\n",
        "dot.edge('AgentB', 'Memory')\n",
        "dot.edge('Memory', 'AgentA')\n",
        "dot.edge('AgentA', 'Judge')\n",
        "dot.render('debate_dag', cleanup=True)\n",
        "print(\"DAG diagram saved as debate_dag.png\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lSGG8p3Utasn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}